{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망으로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터를 만들고 신경망을 훈련시킨 다음 훈련된 모델을 사용하여 챗봇을 만들 것이다.\n",
    "\n",
    "먼저, 필수 라이브러리를 설치하기로 했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (1.7.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (9.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scipy\n",
    "!pip install scikit-learn\n",
    "!pip install pillow\n",
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "Collecting python_version>\"3.7\"\n",
      "  Downloading python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: python-version, tensorflow-gpu\n",
      "    Running setup.py install for tensorflow-gpu: started\n",
      "    Running setup.py install for tensorflow-gpu: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\USER\\AppData\\Local\\Temp\\pip-wheel-gpjic88g'\n",
      "       cwd: C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-yc331n0x\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\n",
      "  Complete output (17 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-yc331n0x\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\setup.py\", line 37, in <module>\n",
      "      raise Exception(TF_REMOVAL_WARNING)\n",
      "  Exception:\n",
      "  \n",
      "  =========================================================\n",
      "  The \"tensorflow-gpu\" package has been removed!\n",
      "  \n",
      "  Please install \"tensorflow\" instead.\n",
      "  \n",
      "  Other than the name, the two packages have been identical\n",
      "  since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  information, see: pypi.org/project/tensorflow-gpu\n",
      "  =========================================================\n",
      "  \n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\USER\\AppData\\Local\\Temp\\pip-record-0ientcf6\\install-record.txt' --single-version-externally-managed --user --prefix= --compile --install-headers 'C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\Include\\tensorflow-gpu'\n",
      "         cwd: C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-yc331n0x\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-yc331n0x\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\setup.py\", line 37, in <module>\n",
      "        raise Exception(TF_REMOVAL_WARNING)\n",
      "    Exception:\n",
      "    \n",
      "    =========================================================\n",
      "    The \"tensorflow-gpu\" package has been removed!\n",
      "    \n",
      "    Please install \"tensorflow\" instead.\n",
      "    \n",
      "    Other than the name, the two packages have been identical\n",
      "    since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "    information, see: pypi.org/project/tensorflow-gpu\n",
      "    =========================================================\n",
      "    \n",
      "    \n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\ProgramData\\Anaconda3\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\pip-install-yc331n0x\\\\tensorflow-gpu_9c9b838ad77f41ffb6ac2c459f029ac0\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\USER\\AppData\\Local\\Temp\\pip-record-0ientcf6\\install-record.txt' --single-version-externally-managed --user --prefix= --compile --install-headers 'C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\Include\\tensorflow-gpu' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 설치\n",
    "\n",
    "우선 이 신경망 구동 챗봇에 필요한 라이브러리를 설치해보았다.\n",
    "Keras는 백엔드에서 텐서플로우(다른 하위 레벨 기계 학습 라이브러리) 를 활용하는 기계 학습 라이브러리이다. 이렇게 케라스를 쓰면 심층 신경망으로 챗봇을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    " \n",
    "from numpy import argmax\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 입력 훈련 데이터\n",
    "\n",
    "먼저 챗봇에 대한 다음 교육 데이터를 포함해야한다.\n",
    "1. X는 사용자가 입력할 수 있는 다양한 입력을 나타내고,\n",
    "2. Y는 입력의 의도를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['Hi',\n",
    "     'Hello',\n",
    "     'How are you?',\n",
    "     'I am making',\n",
    "     'making',\n",
    "     'working',\n",
    "     'studying',\n",
    "     'see you later',\n",
    "     'bye',\n",
    "     'goodbye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ['greeting',\n",
    "     'greeting',\n",
    "     'greeting',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'busy',\n",
    "     'bye',\n",
    "     'bye',\n",
    "     'bye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 비슷한 의도를 가진 여러 개의 다른 문장들이 있다는 것을 주목해야한다. 아직 여기서는 3개의 의도(greeting, busy, bye)만 있지만 프로젝트에 원하는 만큼 추가할 수 있다. 그냥 쉽게 하기 위해서 3개만 넣어뒀다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇이 작동하는 방식은...\n",
    "1. 입력 문장으로부터, 우리는 훈련된 AI 모델을 사용하여 의도를 확인한다.\n",
    "2. 각 의도에 대해, 준비 된 응답을 가지고있는 것이다.\n",
    "\n",
    "예를 들어, 입력의 의도가 인사말에 대한 것임을 확인하면 챗봇에 '안녕하세요'또는 '어떻게 지내십니까?'와 같은 인사말로 응답하도록 요청할 수 있다.\n",
    "\n",
    "기계 학습을 사용하여 입력 문장을 다른 의도로 분류 할 수있는 모델을 만들 것이다. \n",
    "그러면 다음과 같이 만들어야한다..\n",
    "1. 문장과 그 의도에 대한 목록을 포함하고 있는 훈련 데이터(위의 X및  Y)를 작성한다.\n",
    "2. 훈련 데이터를 사용하여 분류기를 훈련한다. \n",
    "3. 입력 문장을 벡터화하고 분류기를 사용하여 의도를 결정한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 텍스트 처리\n",
    "\n",
    "평소와 같이 텍스트 처리부터 시작해야한다.\n",
    "\n",
    "## 3.1 알파벳과 숫자가 아닌 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alpha_numeric_characters(sentence):\n",
    "    new_sentence = ''\n",
    "    for alphabet in sentence:\n",
    "        if alphabet.isalpha() or alphabet == ' ':\n",
    "            new_sentence += alphabet\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    X = [data_point.lower() for data_point in X]\n",
    "    X = [remove_non_alpha_numeric_characters(\n",
    "        sentence) for sentence in X]\n",
    "    X = [data_point.strip() for data_point in X]\n",
    "    X = [re.sub(' +', ' ',\n",
    "                data_point) for data_point in X]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess_data(X)\n",
    "\n",
    "vocabulary = set()\n",
    "for data_point in X:\n",
    "    for word in data_point.split(' '):\n",
    "        vocabulary.add(word)\n",
    "\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문서 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = []\n",
    "\n",
    "def encode_sentence(sentence):\n",
    "    sentence = preprocess_data([sentence])[0]\n",
    "    sentence_encoded = [0] * len(vocabulary)\n",
    "    for i in range(len(vocabulary)):\n",
    "        if vocabulary[i] in sentence.split(' '):\n",
    "            sentence_encoded[i] = 1\n",
    "    return sentence_encoded\n",
    "\n",
    "X_encoded = [encode_sentence(sentence) for sentence in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(Y))\n",
    "\n",
    "Y_encoded = []\n",
    "for data_point in Y:\n",
    "    data_point_encoded = [0] * len(classes)\n",
    "    for i in range(len(classes)):\n",
    "        if classes[i] == data_point:\n",
    "            data_point_encoded[i] = 1\n",
    "    Y_encoded.append(data_point_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 훈련 데이터 및 테스트 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_encoded\n",
    "y_train = Y_encoded\n",
    "X_test = X_encoded\n",
    "y_test = Y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 및 테스트 데이터에 사용하는 데이터 출력 및 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0], [1, 0, 0], [1, 0, 0], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "print (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [1, 0, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 0, 1],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0],\n",
       " [0, 1, 0]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련 데이터를 이용해 신경망을 훈련시키겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 411ms/step - loss: 1.1192\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1093\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0982\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0879\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0799\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0747\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0719\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0709\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0708\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0707\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0702\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0690\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0669\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0643\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0612\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0579\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0548\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0519\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0493\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0470\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0448\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0428\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0407\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0385\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0363\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0339\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0315\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0291\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0266\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0241\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0217\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0193\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0169\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0146\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0122\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0099\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0075\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0051\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0027\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0003\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9979\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9956\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9932\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9908\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9884\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9860\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9836\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9812\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9788\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9764\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9741\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9717\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9693\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9669\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9645\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9621\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9597\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9573\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9549\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9525\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9501\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9477\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9453\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9429\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9405\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9380\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9356\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9332\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9308\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9284\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9259\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9235\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9211\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9186\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9162\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9137\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9113\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9088\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9064\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9039\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9015\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8990\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8965\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8941\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8916\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8891\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8866\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8841\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8816\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8791\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8766\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8741\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8716\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8691\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8666\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8641\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8615\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8590\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8565\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f8c9612c70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=64, activation='sigmoid',\n",
    "                input_dim=len(X_train[0])))\n",
    "model.add(Dense(units=len(y_train[0]), activation='softmax'))\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=SGD(lr=0.01,\n",
    "                            momentum=0.9, nesterov=True))\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 목록 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = [argmax(pred) for pred in model.predict(np.array(X_test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 평가해 봅시다. 모델에 의한 예측과 테스트 데이터를 비교할 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 7\n",
      "Total: 10\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == argmax(y_test[i]):\n",
    "        correct += 1\n",
    "\n",
    "print (\"Correct:\", correct)\n",
    "print (\"Total:\", len(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 챗봇을 테스트해 보겠습니다! 문장을 입력한 다음 신경망에서 예측되는 클래스를 확인합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    print (\"Enter a sentence\")\n",
    "    sentence = input()\n",
    "    prediction= model.predict(np.array([encode_sentence(sentence)]))\n",
    "    print (classes[argmax(prediction)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "챗봇을 멈출 수 없다는 것을 알고 있습니까? 나중에 종료 명령을 추가해야 합니다(이전 노트를 참조하여 수행 방법을 확인하십시오.).\n",
    "\n",
    "일단은 위의 중지 버튼(인터럽트 버튼)을 눌러서 챗봇을 중지하면 됩니다.\n",
    "\n",
    "시도해 보세요. 정지 버튼을 누르고 상자에 뭔가를 입력해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출처:\n",
    "https://blog.eduonix.com/internet-of-things/simple-nlp-based-chatbot-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
